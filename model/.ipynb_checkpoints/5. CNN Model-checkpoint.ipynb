{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get training & testing file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "TRAINING_LOCAL = '/Users/terrycho/dev/workspace/cifar-10/data/training'\n",
    "TRAINING_FILES = []\n",
    "for filename in os.listdir(TRAINING_LOCAL):\n",
    "    TRAINING_FILES.append(str(TRAINING_LOCAL+'/'+filename))\n",
    "    \n",
    "TESTING_LOCAL = '/Users/terrycho/dev/workspace/cifar-10/data/testing'\n",
    "TESTING_FILES = []\n",
    "for filename in os.listdir(TESTING_LOCAL):\n",
    "    TESTING_FILES.append(str(TESTING_LOCAL+'/'+filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data read test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original size :2439\n",
      "shape (32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFPxCJIqCX4hEUfALkSj/D7QmUkdMdpJZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1141fdcd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label : SparseTensorValue(indices=array([[0]]), values=array([4]), dense_shape=array([1]))\n"
     ]
    }
   ],
   "source": [
    "# read tfrecord and print image and label\n",
    "\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tfrecord_filename = TRAINING_FILES[0]\n",
    "\n",
    "def readRecord(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _,serialized_example = reader.read(filename_queue)\n",
    "    \n",
    "    keys_to_features = {\n",
    "      'image_raw': tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "      'label': tf.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    \n",
    "    features = tf.parse_single_example(serialized_example,features= keys_to_features)\n",
    "    \n",
    "    encoded = tf.cast(features['image_raw'],tf.string)\n",
    "    label = tf.cast(features['label'],tf.int64)\n",
    "\n",
    "    return encoded,label\n",
    "    \n",
    "def main():\n",
    "     filename_queue = tf.train.string_input_producer([tfrecord_filename])\n",
    "     encoded,label = readRecord(filename_queue)\n",
    "     \n",
    "     init_op = tf.global_variables_initializer()\n",
    "\n",
    "     with tf.Session() as sess:\n",
    "         sess.run(init_op)\n",
    "    \n",
    "         coord = tf.train.Coordinator()\n",
    "         threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "         \n",
    "         encoded_value,label_value = sess.run([encoded,label])\n",
    "         print('original size :'+str(len(encoded_value)) )\n",
    "         image = Image.open(io.BytesIO(encoded_value))\n",
    "         image_array = np.array(image)\n",
    "         print('shape '+str(image_array.shape ) )\n",
    "         plt.imshow(image)\n",
    "         plt.show()\n",
    "         print('Label : '+str(label_value))\n",
    "\n",
    "         coord.request_stop()\n",
    "         coord.join(threads)\n",
    "         \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 180, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x128c81990>, '_model_dir': '/tmp/cifar-10_trained_model', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "WARNING:tensorflow:From /Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:269: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/cifar-10_trained_model/model.ckpt.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-06-07:24:40\n",
      "INFO:tensorflow:Restoring parameters from /tmp/cifar-10_trained_model/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-06-07:24:40\n",
      "INFO:tensorflow:Saving dict for global step 1: global_step = 1, loss = 2.78441\n",
      "INFO:tensorflow:Validation (step 1): loss = 2.78441, global_step = 1\n",
      "INFO:tensorflow:loss = 2.30958, step = 1\n",
      "INFO:tensorflow:global_step/sec: 2.09105\n",
      "INFO:tensorflow:loss = 1.53088, step = 101 (47.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.00698\n",
      "INFO:tensorflow:loss = 1.42957, step = 201 (49.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.3886\n",
      "INFO:tensorflow:loss = 1.11894, step = 301 (29.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.97289\n",
      "INFO:tensorflow:loss = 1.10197, step = 401 (33.637 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 462 into /tmp/cifar-10_trained_model/model.ckpt.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-06-07:27:40\n",
      "INFO:tensorflow:Restoring parameters from /tmp/cifar-10_trained_model/model.ckpt-462\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-06-07:27:41\n",
      "INFO:tensorflow:Saving dict for global step 462: global_step = 462, loss = 1.1837\n",
      "INFO:tensorflow:Validation (step 462): loss = 1.1837, global_step = 462\n",
      "INFO:tensorflow:global_step/sec: 3.03518\n",
      "INFO:tensorflow:loss = 0.863154, step = 501 (32.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8951\n",
      "INFO:tensorflow:loss = 0.779726, step = 601 (34.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.16894\n",
      "INFO:tensorflow:loss = 0.499484, step = 701 (31.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11488\n",
      "INFO:tensorflow:loss = 0.303843, step = 801 (32.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.94535\n",
      "INFO:tensorflow:loss = 0.393165, step = 901 (33.952 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 999 into /tmp/cifar-10_trained_model/model.ckpt.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-06-07:30:40\n",
      "INFO:tensorflow:Restoring parameters from /tmp/cifar-10_trained_model/model.ckpt-999\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-06-07:30:41\n",
      "INFO:tensorflow:Saving dict for global step 999: global_step = 999, loss = 1.67402\n",
      "INFO:tensorflow:Validation (step 999): loss = 1.67402, global_step = 999\n",
      "INFO:tensorflow:global_step/sec: 2.76768\n",
      "INFO:tensorflow:loss = 0.252148, step = 1001 (36.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.8547\n",
      "INFO:tensorflow:loss = 0.141866, step = 1101 (35.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.87695\n",
      "INFO:tensorflow:loss = 0.104646, step = 1201 (34.759 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0a898033e4b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m#data_dir='./data/',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         train_steps=2000),\n\u001b[0;32m--> 176\u001b[0;31m     OUTDIR)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(experiment_fn, output_dir, schedule, run_config, hparams)\u001b[0m\n\u001b[1;32m    207\u001b[0m   \u001b[0mschedule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_default_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_execute_schedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/learn_runner.pyc\u001b[0m in \u001b[0;36m_execute_schedule\u001b[0;34m(experiment, schedule)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Allowed values for this experiment are: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Schedule references non-callable member %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.pyc\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dir_suffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         )]\n\u001b[0;32m--> 502\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     eval_result = self._call_evaluate(input_fn=self._eval_input_fn,\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, delay_secs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     return self._call_train(input_fn=self._train_input_fn,\n\u001b[1;32m    279\u001b[0m                             \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                             hooks=self._train_monitors + extra_hooks)\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.pyc\u001b[0m in \u001b[0;36m_call_train\u001b[0;34m(self, _sentinel, input_fn, steps, hooks, max_steps)\u001b[0m\n\u001b[1;32m    670\u001b[0m                                    \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                                    \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                                    hooks=hooks)\n\u001b[0m\u001b[1;32m    673\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m       return self._estimator.fit(input_fn=input_fn,\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps)\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    516\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    860\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    970\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/terrycho/anaconda/envs/tensorflow13/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# simple CNN model for CIFAR-10\n",
    "# reference https://www.tensorflow.org/tutorials/layers\n",
    "\n",
    "import tensorflow as tf\n",
    "import os,shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.python.estimator.model_fn import ModeKeys as Modes\n",
    "from tensorflow.contrib.learn import Experiment\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "from tensorflow.contrib.learn.python.learn.utils import (saved_model_export_utils)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "OUTDIR='/tmp/cifar-10_trained_model'\n",
    "\n",
    "#\n",
    "# definining queue\n",
    "#\n",
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _,serialized_example = reader.read(filename_queue)\n",
    "    \n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image_raw':tf.FixedLenFeature([],tf.string),\n",
    "            'label':tf.FixedLenFeature([],tf.int64),\n",
    "        })\n",
    "    \n",
    "    image = tf.image.decode_png(features['image_raw'],channels=3,dtype=tf.uint8)\n",
    "    image.set_shape([32,32,3])\n",
    "    image = tf.cast(image,tf.float32)*(1.0/255)\n",
    "    label = tf.cast(features['label'],tf.int32)\n",
    "    \n",
    "    return image,label\n",
    "\n",
    "def input_fn(filenames,batch_size=100):\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "    \n",
    "    image,label = read_and_decode(filename_queue)\n",
    "    images,labels = tf.train.batch(\n",
    "        [image,label],batch_size=batch_size,\n",
    "        capacity=1000+3*batch_size)\n",
    "    #images : (100,784), labels : (100,1)\n",
    "    \n",
    "    return {'inputs':images},labels\n",
    "\n",
    "def get_input_fn(filenames,batch_size=100):\n",
    "    return lambda: input_fn(filenames,batch_size)\n",
    "\n",
    "def serving_input_fn():\n",
    "    inputs = {'inputs':tf.placeholder(tf.float32,[None,32,32,3])}\n",
    "    return tf.estimator.export.ServingInputReceiver(inputs,inputs)\n",
    "\n",
    "#\n",
    "# define model\n",
    "#\n",
    "def cnn_model_fn(features,labels,mode):\n",
    "    input_layer = tf.reshape(features['inputs'],[-1,32,32,3])\n",
    "    conv1 = tf.layers.conv2d(inputs=input_layer\n",
    "                             ,filters=32\n",
    "                             ,kernel_size=[5,5]\n",
    "                             ,padding=\"same\"\n",
    "                             ,activation=tf.nn.relu)\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "          inputs=pool1,\n",
    "          filters=64,\n",
    "          kernel_size=[5, 5],\n",
    "          padding=\"same\",\n",
    "          activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    pool2_flat = tf.reshape(pool2,[-1,8*8*64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    output_layer = tf.layers.dense(inputs=dropout, units=10)\n",
    "    \n",
    "    #training and evaluation mode\n",
    "    if mode in (Modes.TRAIN,Modes.EVAL):\n",
    "        global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        label_indices = tf.cast(labels,tf.int32)\n",
    "        onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "        loss = tf.losses.softmax_cross_entropy(\n",
    "                  onehot_labels=onehot_labels, logits=output_layer)\n",
    "        tf.summary.scalar('OptimizeLoss',loss)\n",
    "\n",
    "        if mode == Modes.TRAIN:\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "            train_op = optimizer.minimize(loss,global_step=global_step)\n",
    "            return tf.estimator.EstimatorSpec(mode,loss = loss, train_op = train_op)\n",
    "        if mode == Modes.EVAL:\n",
    "            eval_metric_ops = None\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode,loss=loss,eval_metric_ops = eval_metric_ops)\n",
    "        \n",
    "    # prediction mode\n",
    "    if mode == Modes.PREDICT:\n",
    "        predictions={\n",
    "            'classes':tf.argmax(input=output_layer, axis=1),\n",
    "            'probabilities':tf.nn.softmax(output_layer,name=\"softmax_tensor\")\n",
    "        }\n",
    "        export_outputs={\n",
    "            'outputs':tf.estimator.export.PredictOutput(predictions)\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,predictions=predictions,export_outputs=export_outputs) #이부분 코드 상세 조사할것\n",
    "    \n",
    "\n",
    "def build_estimator(model_dir):\n",
    "    return tf.estimator.Estimator(\n",
    "        model_fn = cnn_model_fn,\n",
    "        model_dir = model_dir,\n",
    "        config=tf.contrib.learn.RunConfig(save_checkpoints_secs=180))\n",
    "\n",
    "def generate_experiment_fn(#data_dir,\n",
    "                          train_batch_size = 100,\n",
    "                          eval_batch_size = 100,\n",
    "                          train_steps = 1000,\n",
    "                          eval_steps = 1,\n",
    "                          **experiment_args):\n",
    "    def _experiment_fn(output_dir):\n",
    "        return Experiment(\n",
    "            build_estimator(output_dir),\n",
    "            train_input_fn=get_input_fn(TRAINING_FILES,batch_size=train_batch_size),\n",
    "            eval_input_fn=get_input_fn(TESTING_FILES,batch_size=eval_batch_size),\n",
    "            export_strategies = [saved_model_export_utils.make_export_strategy(\n",
    "                serving_input_fn,\n",
    "                default_output_alternative_key=None,\n",
    "                exports_to_keep=1)\n",
    "            ],\n",
    "            train_steps = train_steps,\n",
    "            eval_steps = eval_steps,\n",
    "            **experiment_args\n",
    "        )\n",
    "    return _experiment_fn\n",
    "\n",
    "shutil.rmtree(OUTDIR, ignore_errors=True) # start fresh each time\n",
    "learn_runner.run(\n",
    "    generate_experiment_fn(\n",
    "        #data_dir='./data/',\n",
    "        train_steps=20000),\n",
    "    OUTDIR)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test exporeted file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load exported model and check import and output parameter from the exporeted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/cifar-10_trained_model/export/Servo/1515221532/variables/variables\n",
      "[u'inputs']\n",
      "[u'probabilities', u'classes']\n"
     ]
    }
   ],
   "source": [
    "export_dir = '{}/export/Servo/{}'.format(\n",
    "    OUTDIR, os.listdir('{}/export/Servo'.format(OUTDIR))[0]\n",
    ")\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "meta_graph = tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)\n",
    "model_signature = meta_graph.signature_def['serving_default']\n",
    "input_signature = model_signature.inputs\n",
    "output_signature = model_signature.outputs\n",
    "\n",
    "print (input_signature.keys())\n",
    "print (output_signature.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label : SparseTensorValue(indices=array([[0]]), values=array([8]), dense_shape=array([1]))\n",
      "Label : SparseTensorValue(indices=array([[0]]), values=array([8]), dense_shape=array([1]))\n",
      "Label : SparseTensorValue(indices=array([[0]]), values=array([4]), dense_shape=array([1]))\n",
      "Label : SparseTensorValue(indices=array([[0]]), values=array([7]), dense_shape=array([1]))\n",
      "Label : SparseTensorValue(indices=array([[0]]), values=array([9]), dense_shape=array([1]))\n",
      "Label : SparseTensorValue(indices=array([[0]]), values=array([9]), dense_shape=array([1]))\n",
      "Label : SparseTensorValue(indices=array([[0]]), values=array([6]), dense_shape=array([1]))\n",
      "Label : SparseTensorValue(indices=array([[0]]), values=array([6]), dense_shape=array([1]))\n",
      "Label : SparseTensorValue(indices=array([[0]]), values=array([0]), dense_shape=array([1]))\n",
      "[array([9, 1, 1, 1, 1, 9, 0, 0, 1]), array([[ 0.11094771,  0.1169503 ,  0.11499836,  0.08466996,  0.09514512,\n",
      "         0.09057096,  0.10095648,  0.0960665 ,  0.072331  ,  0.11736363],\n",
      "       [ 0.11065747,  0.12132746,  0.10911795,  0.07887254,  0.09914542,\n",
      "         0.08661968,  0.09801555,  0.10094192,  0.07747988,  0.1178221 ],\n",
      "       [ 0.10916226,  0.1158918 ,  0.10618202,  0.0847943 ,  0.09247686,\n",
      "         0.09731727,  0.10008767,  0.10095862,  0.08311676,  0.11001246],\n",
      "       [ 0.11645871,  0.12005395,  0.11583704,  0.08118641,  0.09144821,\n",
      "         0.10332819,  0.08746973,  0.10106224,  0.07342011,  0.10973547],\n",
      "       [ 0.10965145,  0.11281993,  0.11200475,  0.07650897,  0.10174202,\n",
      "         0.09464781,  0.10263805,  0.10606059,  0.072554  ,  0.11137237],\n",
      "       [ 0.11258293,  0.11228972,  0.10804425,  0.07879019,  0.09842426,\n",
      "         0.09391116,  0.09825987,  0.094579  ,  0.08603715,  0.11708144],\n",
      "       [ 0.12184969,  0.10608986,  0.10731225,  0.08175318,  0.10206801,\n",
      "         0.09390654,  0.09362116,  0.09860713,  0.08473577,  0.11005642],\n",
      "       [ 0.1150312 ,  0.10782548,  0.10312537,  0.08870936,  0.09905469,\n",
      "         0.09747092,  0.09523672,  0.10534474,  0.08143977,  0.10676174],\n",
      "       [ 0.11002243,  0.12071065,  0.11294936,  0.08636994,  0.09379768,\n",
      "         0.09040808,  0.09440467,  0.09864561,  0.08406347,  0.10862806]], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nimages ={'inputs':image_array}\\nlabels = {}\\n\\neval_data = \\neval_input_fn = tf.estimator.inputs.numpy_input_fn(\\n    x=images,\\n    y=eval_labels,\\n    num_epochs=1,\\n    shuffle=False)\\neval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\\nprint(eval_results)\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read tfrecord and print image and label\n",
    "\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tfrecord_filename = './cifar-10.tfrecord'\n",
    "\n",
    "def readRecord(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _,serialized_example = reader.read(filename_queue)\n",
    "    \n",
    "    keys_to_features = {\n",
    "      'image_raw': tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "      'label': tf.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    \n",
    "    features = tf.parse_single_example(serialized_example,features= keys_to_features)\n",
    "    \n",
    "    encoded = tf.cast(features['image_raw'],tf.string)\n",
    "    label = tf.cast(features['label'],tf.int64)\n",
    "\n",
    "    return encoded,label\n",
    "    \n",
    "def main():\n",
    "     filename_queue = tf.train.string_input_producer([tfrecord_filename])\n",
    "     encoded,label = readRecord(filename_queue)\n",
    "     \n",
    "     init_op = tf.global_variables_initializer()\n",
    "\n",
    "     images=[]\n",
    "     labels=[]\n",
    "\n",
    "     with tf.Session() as sess:\n",
    "         sess.run(init_op)\n",
    "    \n",
    "         coord = tf.train.Coordinator()\n",
    "         threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "         for i in range(1,10):\n",
    "             encoded_value,label_value = sess.run([encoded,label])\n",
    "\n",
    "             image = Image.open(io.BytesIO(encoded_value))\n",
    "             image_array = np.array(image,'f')*(1.0/255)\n",
    "             images.append(image_array)\n",
    "             labels.append(label_value)\n",
    "             #print('shape '+str(image_array.shape ) )\n",
    "             #print(image_array.dtype)\n",
    "             #print(image_array)\n",
    "             #plt.imshow(image)\n",
    "             #plt.show()\n",
    "             print('Label : '+str(label_value))\n",
    "\n",
    "         feed_dict = {sess.graph.get_tensor_by_name(input_signature['inputs'].name):images}\n",
    "         classes = sess.graph.get_tensor_by_name(output_signature['classes'].name)\n",
    "         probabilities = sess.graph.get_tensor_by_name(output_signature['probabilities'].name)\n",
    "         results = sess.run([classes,probabilities], feed_dict=feed_dict)\n",
    "         print (results)\n",
    "        \n",
    "         coord.request_stop()\n",
    "         coord.join(threads)\n",
    "         \n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
